# Projeto de ETL e Modelagem de Dados no Setor de Seguros

![Capa](images/capa.png)

## Contexto do NegÃ³cio ğŸ’¼

O setor de seguros desempenha um papel crucial na economia, oferecendo proteÃ§Ã£o financeira contra diversos riscos. No Brasil, a SuperintendÃªncia de Seguros Privados (SUSEP) Ã© o Ã³rgÃ£o responsÃ¡vel por regular e supervisionar o mercado de seguros, garantindo sua estabilidade e transparÃªncia. Apesar da vasta quantidade de dados pÃºblicos disponibilizados pela SUSEP, a falta de estruturaÃ§Ã£o e o formato muitas vezes nÃ£o padronizado desses dados representam desafios significativos. Essa realidade sublinha a importÃ¢ncia de desenvolver processos eficientes de ETL e a criaÃ§Ã£o de Data Warehouses que possam transformar esses dados brutos em informaÃ§Ãµes estruturadas, acessÃ­veis e analisÃ¡veis, especialmente em nichos especÃ­ficos como o seguro garantia e a fianÃ§a locatÃ­cia.

## Objetivo ğŸ¯
Este projeto visa a elaboraÃ§Ã£o de um processo completo de ETL a partir de fontes de dados pÃºblicas, especificamente dados da SUSEP, e a criaÃ§Ã£o de um Data Warehouse otimizado para os ramos de seguro garantia e fianÃ§a locatÃ­cia. O objetivo Ã© nÃ£o apenas organizar e estruturar os dados de maneira eficaz, mas tambÃ©m facilitar anÃ¡lises profundas que possam apoiar decisÃµes estratÃ©gicas e promover inovaÃ§Ãµes no setor de seguros.

## TÃ³picosğŸ“Œ
- [VisÃ£o GeralğŸŒ](#visÃ£o-geral)
- [Ferramentas e Tecnologias UtilizadasğŸ› ï¸](#ferramentas-e-tecnologias-utilizadas%EF%B8%8F)
- [DadosğŸ“Š](#dados)
- [Modelagem do Data WarehouseğŸ“¦](#modelagem-do-data-warehouse)
- [ElaboraÃ§Ã£o dos Fluxos de CargağŸ”€](#elaboraÃ§Ã£o-dos-fluxos-de-carga)
    - [Carga da DimensÃ£o Ramoâœï¸](#carga-da-dimensÃ£o-ramo%EF%B8%8F)
    - [Carga da DimensÃ£o EmpresağŸ¢](#carga-da-dimensÃ£o-empresa)
    - [Carga da DimensÃ£o Tempoâ³](#carga-da-dimensÃ£o-tempo)
    - [Carga da Tabela de FatoğŸ“ˆ](#carga-da-tabela-de-fato)
- [ExportaÃ§Ã£o da Base de DadosğŸ“¤](#exportaÃ§Ã£o-da-base-de-dados)
- [AtualizaÃ§Ã£o dos DadosğŸ”„](#atualizaÃ§Ã£o-dos-dados)
- [ConclusÃµes e RecomendaÃ§ÃµesğŸ’¡](#conclusÃµes-e-recomendaÃ§Ãµes)
- [ConsideraÃ§Ãµes FinaisğŸ“](#consideraÃ§Ãµes-finais)
- [CrÃ©ditosğŸ‘](#crÃ©ditos)
- [LicenÃ§aÂ©ï¸](#licenÃ§a%EF%B8%8F)
- [Disclaimerâš ï¸](#disclaimer%EF%B8%8F)

## VisÃ£o GeralğŸŒ

### Etapa 1 - Coleta de dados:
Nesta etapa inicial, realizar a coleta de dados diretamente do site da SUSEP e analisar os dados e a documentaÃ§Ã£o disponÃ­vel. Esse processo visa entender as necessidades de informaÃ§Ã£o e preparar a base para a modelagem eficaz do Data Warehouse.

### Etapa 2 - Modelagem do Data Warehouse:
ApÃ³s a coleta e anÃ¡lise dos dados, a fase seguinte envolve modelar o Data Warehouse. Usar o SQL Power Architect para desenvolver o modelo que organiza e estrutura os dados de maneira lÃ³gica e eficiente. Com o modelo pronto, executar o script no SQL Server 2022 para estabelecer a estrutura do Data Warehouse.

### Etapa 3 - ElaboraÃ§Ã£o dos Fluxos de Carga:
Com a estrutura do Data Warehouse estabelecida, elaborar e implementar os fluxos de carga de dados. Esses fluxos, essenciais para a integraÃ§Ã£o dos dados no sistema, serÃ£o desenvolvidos no Visual Studio 2022, utilizando o SSIS para realizar as operaÃ§Ãµes de extraÃ§Ã£o, transformaÃ§Ã£o e carga (ETL). Esta etapa garante que os dados coletados sejam processados corretamente e carregados no Data Warehouse.

### Etapa 4 - ExportaÃ§Ã£o do Data Warehouse:
Por fim, exportar a base de dados do Data Warehouse em formato de arquivos CSV. Este procedimento facilita o acesso e a distribuiÃ§Ã£o dos dados, permitindo seu uso para anÃ¡lises futuras e compartilhamento conforme necessÃ¡rio. A exportaÃ§Ã£o dos dados conclui o projeto, deixando os dados organizados e acessÃ­veis.

## Ferramentas e Tecnologias UtilizadasğŸ› ï¸

- **SQL Server Integration Services (SSIS)**: Ferramenta utilizada para desenvolver soluÃ§Ãµes de integraÃ§Ã£o de dados, como extraÃ§Ã£o, transformaÃ§Ã£o e carga (ETL), essencial para alimentar o Data Warehouse.

- **SQL Power Architect**: Aplicativo utilizado para modelar o Data Warehouse, permitindo uma visualizaÃ§Ã£o grÃ¡fica das tabelas, relacionamentos e fluxos de dados, facilitando o projeto e a organizaÃ§Ã£o da estrutura de dados.

- **SQL Server 2022**: Sistema de gerenciamento de banco de dados utilizado para hospedar o Data Warehouse, oferecendo uma plataforma robusta e segura para o armazenamento e a gestÃ£o dos dados coletados e processados.

- **Visual Studio 2022**: Ambiente de desenvolvimento integrado (IDE) empregado para criar os fluxos de trabalho do SSIS, permitindo a elaboraÃ§Ã£o detalhada dos processos de ETL e a integraÃ§Ã£o com o SQL Server.

## DadosğŸ“Š
Os dados utilizados para esse projeto sÃ£o pÃºblicos e podem sem baixados no site da [SUSEP](https://www2.susep.gov.br/menuestatistica/ses/principal.aspx), assim como sua documentaÃ§Ã£o.

**InformaÃ§Ãµes da SUSEP Ã  respeito dos dados:**
 Os dados apresentados foram extraÃ­dos diretamente dos FormulÃ¡rios de InformaÃ§Ãµes PeriÃ³dicas (FIP), enviados Ã  SUSEP pelas companhias seguradoras, resseguradoras, entidades abertas de previdÃªncia privada e sociedades de capitalizaÃ§Ã£o, em atendimento Ã s normas vigentes, e podem sofrer alteraÃ§Ã£o atravÃ©s de recargas de dados, apÃ³s anÃ¡lises realizadas pelos setores responsÃ¡veis.

## Modelagem do Data WarehouseğŸ“¦
O modelo foi criado utilizando o SQL Power Architect e o script resultante foi executado no SQL Server 2022, para que fosse carregado mais tarde.

**Esquema Power Architect:**
![Esquema Power Architect](images/dw_schema_power_architect.png)
**Esquema SQL Server 2022:**
![Esquema SQL Server](images/dw_schema_sql_server.png)
O design adotado pelo modelo Ã© estruturado em formato de estrela, onde as tabelas sÃ£o identificadas por um ID numÃ©rico e inteiro, visando otimizar o desempenho das buscas. AlÃ©m disso, as tabelas dimensionais tÃªm configurada a funcionalidade de incremento automÃ¡tico, permitindo que os IDs sejam gerados e preenchidos de forma automÃ¡tica.

### DimensÃµes ğŸ“
Este Ã© um esboÃ§o detalhado da concepÃ§Ã£o do Data Warehouse, que foi realizada mediante a anÃ¡lise das fontes de dados e a identificaÃ§Ã£o dos dados mais pertinentes no Ã¢mbito do seguro garantia e da fianÃ§a locatÃ­cia.

- **Empresa:**
    - Inputs:
        - CÃ³digo da Empresa
        - Nome da Empresa
        - PatrimÃ´nio LÃ­quido Ajustado
        - Limite de RetenÃ§Ã£o para Seguro Garantia
        - Limite de RetenÃ§Ã£o para FianÃ§a LocatÃ­cia
    - Atributos:
        - Porte (baseado no PatrimÃ´nio LÃ­quido Ajustado)
        - Apetite ao Risco de Seguro Garantia (baseado no Limite de RetenÃ§Ã£o)
        - Apetite ao Risco de FianÃ§a LocatÃ­cia
    - Hierarquias:
        - Grupo EconÃ´mico:
            - NÃ­veis: Empresa < Grupo EconÃ´mico
    - Arquivos da fonte:
        - Ses_grupos_economicos.csv
        - Ses_limite_ret.csv
        - Ses_pl_margem.csv

- **Ramo:**
    - Inputs:
        - CÃ³digo do ramo
        - Nome do ramo
    - Atributos:
        - Seguro Garantia (Booleano)
    - Hierarquia:
        - Grupamento de Ramo:
            - NÃ­veis: Ramo < Grupo
    - Arquivos da fonte:
        - Ses_ramos.csv
        - ses_gruposramos.csv

- **Tempo:**
    - Inputs:
        - Ano e mÃªs da informaÃ§Ã£o - AAAAMM
    - Hierarquias:
        - CalendÃ¡rio:
            - NÃ­veis: MÃªs < Trimestre < Semestre < Ano
    - Arquivos da fonte:
        - Ses_seguros.csv

### Medidas ğŸ“
- **Inputs:**
    - PrÃªmio Direto
    - PrÃªmio de Seguros
    - PrÃªmio Ganho
    - RVNE (PrÃªmios de Riscos Vigentes e NÃ£o Emitidos)
    - Sinistros Ocorridos
    - Despesa Comercial (Custo de AquisiÃ§Ã£o)
    - Despesas com Resseguros
    - Receitas com Resseguros
    - PPNG (ProvisÃ£o de PrÃªmios nÃ£o Ganhos)
    - PPNG RVNE (ProvisÃ£o de PrÃªmios nÃ£o Ganhos de Riscos Vigentes e NÃ£o Emitidos)
    - PSL (ProvisÃ£o de Sinistros a Liquidar)
    - IBNR (ProvisÃ£o de Sinistros Ocorridos e NÃ£o Avisados)
    
- **Calculados:**
    - Sinistralidade: [Sinistros Ocorridos]/[PrÃªmio Ganho]
    - Lucratividade: [PrÃªmio Ganho] - [Sinistros Ocorridos]
    - Rentabilidade: ([Lucratividade]/[PrÃªmio Ganho])*100
    - Resultado de Resseguro ([Receitas com Resseguros] - [Despesas com Resseguros])

- **Arquivos da fonte:**
    - Ses_seguros.csv
    - ses_provramos.csv

## ElaboraÃ§Ã£o dos Fluxos de CargağŸ”€
![Fluxo ETL](images/fluxo_etl.png)
O fluxo completo envolve, primeiramente, o carregamento das tabelas dimensionais de ramo, empresa e tempo, seguido pela carga da tabela de fato. HÃ¡ tambÃ©m a etapa de exclusÃ£o dos dados da tabela de fato em cada execuÃ§Ã£o, dado que as informaÃ§Ãµes das medidas se atualizam com frequÃªncia. Essa abordagem facilita o recarregamento da tabela do zero, evitando o acÃºmulo desnecessÃ¡rio de dados e promovendo maior eficiÃªncia no fluxo.

### Carga da DimensÃ£o Ramoâœï¸
![Carga DimensÃ£o Ramo](images/carga_dim_ramo.png)
Durante esta fase, os dados relacionados aos ramos e seus agrupamentos foram extraÃ­dos, compilados e inseridos no Data Warehouse. Adicionalmente, implementou-se o atributo booleano Seguro Garantia, utilizado como critÃ©rio de seleÃ§Ã£o para os ramos 0775 e 0776, os quais correspondem aos segmentos do seguro garantia.

### Carga da DimensÃ£o EmpresağŸ¢
![Carga DimensÃ£o Empresa 1](images/carga_dim_empresa1.png)
Neste passo, estabeleceu-se uma conexÃ£o com o arquivo Ses_grupos_economicos.csv para obter os dados fundamentais das empresas, como nome e cÃ³digo. Posteriormente, a conexÃ£o com o arquivo Ses_pl_margem.csv permitiu a extraÃ§Ã£o do patrimÃ´nio lÃ­quido das companhias. O principal desafio residia em capturar somente as informaÃ§Ãµes mais atualizadas, uma vez que o banco de dados contÃ©m uma coluna de data, e houve variaÃ§Ãµes nas empresas com o mesmo cÃ³digo ao longo do tempo. Para superar essa questÃ£o, utilizou-se o recurso de agregaÃ§Ã£o do Integration Services, o qual foi empregado para selecionar exclusivamente os cÃ³digos de empresa com a data mais recente.

![Carga DimensÃ£o Empresa 2](images/carga_dim_empresa2.png)
Nesta fase, desenvolveu-se o atributo Porte, fundamentado nos valores de patrimÃ´nio lÃ­quido. A classificaÃ§Ã£o do porte das empresas foi dividida em quatro categorias: Iniciante, IntermediÃ¡rio, Consolidado e LÃ­der. Esta segmentaÃ§Ã£o baseou-se na distribuiÃ§Ã£o dos dados em quatro quartis. A determinaÃ§Ã£o dos valores especÃ­ficos foi realizada por meio de um script SQL aplicado a uma tabela de teste, disponÃ­vel na tabela 'scripts' deste repositÃ³rio, que inclui uma amostra dos dados. Contudo, esses parÃ¢metros sÃ£o flexÃ­veis e podem ser ajustados conforme a necessidade do usuÃ¡rio.

![Carga DimensÃ£o Empresa 3](images/carga_dim_empresa3.png)
Neste ponto, realizou-se a conexÃ£o com o arquivo Ses_limite_ret.csv para capturar as informaÃ§Ãµes relativas ao limite de retenÃ§Ã£o especificamente para os ramos de seguro-garantia (ramos 0775 e 0776) e fianÃ§a locatÃ­cia (ramo 0746). Foi selecionado apenas as linhas que continham as datas mais atuais. ApÃ³s essa seleÃ§Ã£o, os dados foram integrados com os demais arquivos CSV.

![Carga DimensÃ£o Empresa 4](images/carga_dim_empresa4.png)
Finalmente, os atributos referentes ao apetite ao risco foram determinados, sendo categorizados em Pequeno, MÃ©dio e Grande. A definiÃ§Ã£o dos intervalos de valores seguiu um mÃ©todo similar ao utilizado para o atributo Porte, com a distribuiÃ§Ã£o dos dados em trÃªs quartis. No entanto, esses valores sÃ£o ajustÃ¡veis de acordo com as preferÃªncias do usuÃ¡rio. Os dados resultantes foram entÃ£o armazenados no Data Warehouse.

### Carga da DimensÃ£o Tempoâ³
![Carga DimensÃ£o Tempo](images/carga_dim_tempo.png)
Na dimensÃ£o tempo, as datas foram obtidas a partir do arquivo que inclui os dados para a tabela de fato. AlÃ©m disso, foram gerados os cÃ³digos e os descritores correspondentes ao ano, mÃªs, trimestre e semestre. Por fim, essas informaÃ§Ãµes foram registradas no Data Warehouse.

### Carga da Tabela de FatoğŸ“ˆ
![Carga Fato](images/carga_fato1.png)
Para realizar o carregamento da tabela de fato, foi preciso utilizar dois arquivos provenientes da base de dados pÃºblica para a extraÃ§Ã£o de todas as medidas relevantes. O processo comeÃ§a com a seleÃ§Ã£o especÃ­fica dos ramos de interesse, seguida pela conversÃ£o dos dados para o formato apropriado. Em seguida, aplica-se um filtro para considerar apenas os dados a partir de 2018, evitando assim o excesso de carga na base de dados. Os arquivos sÃ£o entÃ£o unificados atravÃ©s de uma operaÃ§Ã£o de junÃ§Ã£o, e na fase subsequente, os dados sÃ£o agrupados segundo os cÃ³digos de tempo, empresa e ramo. Isso Ã© necessÃ¡rio porque a base de dados pode apresentar mÃºltiplas entradas para as mesmas trÃªs dimensÃµes, nesse caso, o valor das medidas Ã© somado.

![Carga Fato](images/carga_fato2.png)
Finalmente, a etapa conclusiva do carregamento da tabela de fato envolve a identificaÃ§Ã£o dos IDs nas dimensÃµes, realizada por meio de uma busca (lookup) utilizando os cÃ³digos naturais encontrados tanto nos arquivos de origem quanto nas dimensÃµes previamente carregadas. Adicionalmente, Ã© aplicada a regra de atribuir o valor zero na ausÃªncia de um ID correspondente. ApÃ³s esta operaÃ§Ã£o, os dados sÃ£o efetivamente transferidos para o Data Warehouse.

## ExportaÃ§Ã£o da Base de DadosğŸ“¤
ApÃ³s a conclusÃ£o do carregamento no Data Warehouse, as tabelas foram exportadas para arquivos no formato CSV, usando a funcionalidade de exportaÃ§Ã£o disponÃ­vel no SQL Server 2022. Esse passo permite que os usuÃ¡rios acessem os dados facilmente, facilitando a criaÃ§Ã£o de visualizaÃ§Ãµes e a anÃ¡lise para obtenÃ§Ã£o de insights valiosos.

## AtualizaÃ§Ã£o dos DadosğŸ”„
UsuÃ¡rios interessados em manter sua base de dados sempre atualizada podem fazer o download dos arquivos mais recentes no site da [SUSEP](https://www2.susep.gov.br/menuestatistica/ses/principal.aspx). ApÃ³s substituir os arquivos antigos pela versÃ£o mais recente na pasta 'data' deste diretÃ³rio, Ã© possÃ­vel executar novamente o processo atravÃ©s do Visual Studio 2022. Os scripts necessÃ¡rios para a configuraÃ§Ã£o do Data Warehouse estÃ£o disponÃ­veis na pasta 'scripts', facilitando a manutenÃ§Ã£o e a atualizaÃ§Ã£o dos dados.

## ConclusÃµes e RecomendaÃ§ÃµesğŸ’¡

Ao enfrentar os desafios de estruturaÃ§Ã£o de dados no setor de seguros, este projeto destacou a importÃ¢ncia de um Data Warehouse bem estruturado e de processos ETL eficientes. Os dados da SUSEP, uma vez organizados e acessÃ­veis, abrem caminho para anÃ¡lises profundas e informadas, especialmente em Ã¡reas como seguro garantia e fianÃ§a locatÃ­cia. Recomendamos vivamente a elaboraÃ§Ã£o de dashboards interativos que permitam aos usuÃ¡rios visualizar e compreender melhor os dados. AlÃ©m disso, o desenvolvimento de modelos de machine learning com base nesses dados pode revelar padrÃµes ocultos, prever tendÃªncias e otimizar decisÃµes estratÃ©gicas. Essas iniciativas nÃ£o sÃ³ promoverÃ£o a inovaÃ§Ã£o no setor, mas tambÃ©m reforÃ§arÃ£o a importÃ¢ncia de prÃ¡ticas de dados avanÃ§adas para uma tomada de decisÃ£o mais eficaz e fundamentada.

## ConsideraÃ§Ãµes FinaisğŸ“

O projeto destaca a importÃ¢ncia da anÃ¡lise de dados no setor de seguros, transformando dados pÃºblicos em insights valiosos. A abordagem adotada aqui deve servir de referÃªncia para futuras iniciativas, promovendo melhores prÃ¡ticas de gestÃ£o de dados e anÃ¡lise no setor.

## CrÃ©ditosğŸ‘

Agradecemos Ã  SUSEP pela disponibilizaÃ§Ã£o dos dados que fundamentaram este projeto, utilizados com fins educacionais e nÃ£o comerciais, reforÃ§ando o valor da transparÃªncia e dos dados abertos no desenvolvimento do setor de seguros.

## LicenÃ§aÂ©ï¸
Este projeto estÃ¡ licenciado sob a [Creative Commons Attribution-NonCommercial 4.0 International License (CC BY-NC 4.0)](https://creativecommons.org/licenses/by-nc/4.0/). Use e compartilhe de forma responsÃ¡vel.

## Disclaimerâš ï¸
Este projeto foi desenvolvido exclusivamente para fins educacionais e de demonstraÃ§Ã£o das habilidades analÃ­ticas e de manipulaÃ§Ã£o de dados do autor, sem quaisquer objetivos comerciais ou de lucro. Todos os dados utilizados sÃ£o de domÃ­nio pÃºblico ou foram adquiridos e utilizados em conformidade com as diretrizes e termos de uso das respectivas fontes de dados.

As tÃ©cnicas de coleta de dados e anÃ¡lise aplicadas neste projeto refletem as habilidades do autor e nÃ£o tÃªm a intenÃ§Ã£o de violar quaisquer diretrizes de direitos autorais ou leis aplicÃ¡veis. O autor nÃ£o se responsabiliza por interpretaÃ§Ãµes ou conclusÃµes de terceiros baseadas nas anÃ¡lises apresentadas. O uso das informaÃ§Ãµes fornecidas neste projeto Ã© de responsabilidade exclusiva do usuÃ¡rio. Ã‰ crucial que qualquer uso dos mÃ©todos ou dados apresentados aqui seja feito com cautela e em conformidade estrita com as leis e regulamentos aplicÃ¡veis.